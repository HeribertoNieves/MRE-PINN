{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v006.ib.bridges2.psc.edu\n",
      "/ocean/projects/asc170022p/mtragoza/mre-pinn/notebooks\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "!hostname\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..')\n",
    "%aimport mre_pinn\n",
    "\n",
    "sys.path.append('../../param_search')\n",
    "%aimport param_search\n",
    "ps = param_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPMI 2023 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the job template and name format\n",
    "\n",
    "template = '''\\\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --account=asc170022p\n",
    "#SBATCH --partition=GPU-shared\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH -o %J.stdout\n",
    "#SBATCH -e %J.stderr\n",
    "#SBATCH --mail-type=all\n",
    "\n",
    "hostname\n",
    "pwd\n",
    "source activate MRE-PINN\n",
    "\n",
    "python ../../../train.py \\\\\n",
    "    --data_root ../../../data/BIOQIC \\\\\n",
    "    --data_name fem_box \\\\\n",
    "    --frequency {frequency} \\\\\n",
    "    --xyz_slice {xyz_slice} \\\\\n",
    "    --pde_name {pde_name} \\\\\n",
    "    --omega0 {omega0} \\\\\n",
    "    --n_layers {n_layers} \\\\\n",
    "    --n_hidden {n_hidden} \\\\\n",
    "    --activ_fn {activ_fn} \\\\\n",
    "    --learning_rate {learning_rate} \\\\\n",
    "    --pde_loss_wt {pde_loss_wt} \\\\\n",
    "    --data_loss_wt {data_loss_wt} \\\\\n",
    "    --batch_size {batch_size} \\\\\n",
    "    --n_domain {n_domain} \\\\\n",
    "    --n_iters {n_iters} \\\\\n",
    "    --test_every {test_every} \\\\\n",
    "    --save_every {save_every} \\\\\n",
    "    --save_prefix {job_name}    \n",
    "'''\n",
    "name = 'train_{frequency}_{xyz_slice}_{pde_name}_{omega0}_{activ_fn}_{pde_distrib}'\n",
    "\n",
    "# define the parameter space\n",
    "\n",
    "param_space = ps.ParamSpace(\n",
    "    frequency=[80],\n",
    "    xyz_slice=['1D'],\n",
    "    pde_name=['helmholtz', 'hetero'],\n",
    "    omega0=[4, 8, 16],\n",
    "    n_layers=5,\n",
    "    n_hidden=16,\n",
    "    activ_fn=['s', 't'],\n",
    "    learning_rate=1e-3,\n",
    "    pde_loss_wt=1e-8,\n",
    "    data_loss_wt=1,\n",
    "    batch_size=80,\n",
    "    n_domain=128-80,\n",
    "    pde_distrib=['pseudo', 'sobol', 'uniform'],\n",
    "    n_iters=25000,\n",
    "    test_every=1000,\n",
    "    save_every=1000\n",
    ")\n",
    "\n",
    "len(param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "expt_name = '2022-07-25_1D_fixed'\n",
    "\n",
    "jobs = ps.submit(template, name, param_space, work_dir=expt_name, verbose=True)\n",
    "jobs.to_csv(f'{expt_name}.jobs')\n",
    "\n",
    "#jobs = pd.read_csv(f'{expt_name}.jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "status_cols = ['job_name', 'job_state', 'node_id', 'runtime', 'stdout', 'stderr']\n",
    "ps.status(jobs)[status_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ps.metrics(jobs)\n",
    "\n",
    "# did all models train to 25k iterations?\n",
    "assert (metrics.groupby('job_name')['iteration'].max() == 25e3).all()\n",
    "\n",
    "# get the final test evaluations\n",
    "metrics = metrics[metrics.iteration == 25e3]\n",
    "\n",
    "param_cols = ['pde_name', 'omega0', 'activ_fn', 'pde_distrib'] # experimental parameters\n",
    "index_cols = ['variable_name', 'spatial_frequency_bin', 'spatial_region'] # metric identifiers\n",
    "metric_cols = ['mean_squared_abs_value', 'power_density', 'mean_abs_value'] # metric values\n",
    "\n",
    "metrics = metrics.groupby(param_cols + index_cols, sort=False)[metric_cols].mean().unstack(level=[4])\n",
    "\n",
    "def metric_map(t):\n",
    "    metric_name, var_name = t\n",
    "    metric_name = {\n",
    "        'mean_squared_abs_value': 'MSAV',\n",
    "        'mean_abs_value': 'MAV',\n",
    "        'power_density': 'SPD'\n",
    "    }[metric_name]\n",
    "    new_col_name = f'{var_name}_{metric_name}'\n",
    "    new_col_name = new_col_name.replace('diff_MSAV', 'pred_MSAE')\n",
    "    new_col_name = new_col_name.replace('f_sum_MSAV', 'PDE_MSAE')\n",
    "    new_col_name = new_col_name.replace('diff_MAV', 'pred_MAD')\n",
    "    return new_col_name\n",
    "\n",
    "metrics.columns = [metric_map(t) for t in metrics.columns.to_flat_index()]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ps.plot(\n",
    "    metrics.reset_index(),\n",
    "    x=param_cols,\n",
    "    y=['u_pred_MSAE'],\n",
    "    height=3,\n",
    "    width=2.25,\n",
    "    legend=False,\n",
    "    tight=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much all models fit the wave field to a very low error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ps.plot(\n",
    "    metrics.reset_index(),\n",
    "    x=param_cols,\n",
    "    y=['PDE_MSAE'],\n",
    "    height=3,\n",
    "    width=2.5,\n",
    "    legend=False,\n",
    "    tight=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is much more variance in minimizing the PDE residual, and no clear trends jump out at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ps.plot(\n",
    "    metrics.reset_index(),\n",
    "    x=param_cols,\n",
    "    y=['PDE_MSAE'],\n",
    "    hue='pde_name',\n",
    "    height=4, width=2.5,\n",
    "    tight=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall it seems that the Helmholtz PDE residual was easier to minimize than the heterogeneous PDE. There also appears to be a trend where the residuals are lower (for both PDEs) when omega0 is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ps.plot(\n",
    "    metrics.reset_index(),\n",
    "    x=param_cols,\n",
    "    y=['mu_pred_MAD'],\n",
    "    height=8, width=3,\n",
    "    tight=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are looking at the median absolute deviation of the predict stiffness in each of the regions. There is a very clear signal in the PDE name plot: Using the heterogeneous PDE results in lower error in the predicted stiffness per region, compared to the Helmholtz PDE. There may be a trend in the omeg0 and activ_fn plots as well, but it's less clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ps.plot(\n",
    "    metrics.reset_index(),\n",
    "    x=param_cols,\n",
    "    y=['mu_pred_MAD'],\n",
    "    hue='pde_name',\n",
    "    height=4, width=3,\n",
    "    tight=True\n",
    ")\n",
    "fig.savefig('1d_experiment_mu_pred_MAD.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot emphasizes a clear and statistically significant signal from using the heterogeneous PDE instead of the Helmholtz PDE, resulting in more accurate predicted stiffness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = metrics.reset_index()\n",
    "m['Mean % mu error (by region)'] = m['mu_pred_MAD'] / m['mu_true_MAV'] * 100\n",
    "\n",
    "fig = ps.plot(\n",
    "    m,\n",
    "    x=param_cols,\n",
    "    y=['Mean % mu error (by region)'],\n",
    "    hue='pde_name',\n",
    "    height=4, width=3,\n",
    "    tight=True\n",
    ")\n",
    "fig.savefig('1d_experiment_mu_pred_MAD_relative.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = metrics.reset_index().groupby(param_cols).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = sns.lmplot(data=agg.reset_index(), x='PDE_MSAE', y='mu_pred_MAD', hue='pde_name')\n",
    "fig.savefig('1d_experiment_mu_pred_MAD_corr.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though using the heterogeneous PDE instead of Helmholtz consistently improves reconstruction quality, there is not a clear correlation between the PDE residual and the reconstruction quality. If anything, the Helmholtz residual is more strongly correlated with mu error, even though mu error is higher in absolute terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = metrics.reset_index()\n",
    "\n",
    "fig = ps.plot(\n",
    "    m[m.pde_name == 'hetero'].copy(),\n",
    "    x=param_cols[1:],\n",
    "    y=['mu_pred_MAD'],\n",
    "    height=5.5, width=3,\n",
    "    tight=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not seem to be a relationship with the PDE distribution. So even though I was correct that the Helmholtz PDE seems worse then heterogeneous, the reason why does not seem to be related to the domain sampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRE-PINN",
   "language": "python",
   "name": "mre-pinn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
