{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dv002.bridges2.psc.edu\n",
      "/ocean/projects/asc170022p/mtragoza/mre-pinn/notebooks\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "!hostname\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('..')\n",
    "%aimport mre_pinn\n",
    "\n",
    "sys.path.append('../../param_search')\n",
    "%aimport param_search\n",
    "ps = param_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PINNs conditioned on MRI anatomic images\n",
    "\n",
    "The objective is to see whether we can improve the performance of PINNs at elasticity reconstruction over a baseline method by conditioning the model on MRI anatomical images. We will use the BIOQIC phantom data set and evaluate at each of the different data frequencies separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the job template and name format\n",
    "\n",
    "template = '''\\\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --account=asc170022p\n",
    "#SBATCH --partition=GPU-shared\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH -o %J.stdout\n",
    "#SBATCH -e %J.stderr\n",
    "#SBATCH --mail-type=all\n",
    "\n",
    "hostname\n",
    "pwd\n",
    "source activate MRE-PINN\n",
    "\n",
    "python ../../../train.py \\\\\n",
    "    --data_root ../../../data/BIOQIC \\\\\n",
    "    --data_name phantom \\\\\n",
    "    --frequency {frequency} \\\\\n",
    "    --xyz_slice {xyz_slice} \\\\\n",
    "    --noise_ratio 0.0 \\\\\n",
    "    --pde_name {pde_name} \\\\\n",
    "    --omega0 {omega0} \\\\\n",
    "    --n_layers {n_layers} \\\\\n",
    "    --n_hidden {n_hidden} \\\\\n",
    "    --activ_fn {activ_fn} \\\\\n",
    "    --polar {polar} \\\\\n",
    "    --conditional {conditional} \\\\\n",
    "    --optimizer adam \\\\\n",
    "    --learning_rate {learning_rate} \\\\\n",
    "    --pde_loss_wt {pde_loss_wt} \\\\\n",
    "    --data_loss_wt {data_loss_wt} \\\\\n",
    "    --batch_size {batch_size} \\\\\n",
    "    --n_iters {n_iters} \\\\\n",
    "    --test_every {test_every} \\\\\n",
    "    --save_every {save_every} \\\\\n",
    "    --save_prefix {job_name}\n",
    "'''\n",
    "name = 'train_{frequency}_{xyz_slice}_{pde_name}_{omega0}_{polar}_{conditional}'\n",
    "\n",
    "# define the parameter space\n",
    "\n",
    "param_space = ps.ParamSpace(\n",
    "    frequency=[50, 60, 70, 80, 90, 100],\n",
    "    xyz_slice=['2D'],\n",
    "    pde_name=['helmholtz', 'hetero'],\n",
    "    omega0=[1, 4, 16],\n",
    "    n_layers=[5],\n",
    "    n_hidden=[128],\n",
    "    activ_fn=['s'],\n",
    "    polar=[0, 1],\n",
    "    conditional=[0, 1],\n",
    "    learning_rate=1e-4,\n",
    "    pde_loss_wt=1e-8,\n",
    "    data_loss_wt=1,\n",
    "    batch_size=128,\n",
    "    n_iters=250000,\n",
    "    test_every=1000,\n",
    "    save_every=10000\n",
    ")\n",
    "\n",
    "len(param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 144.22it/s]\n",
      "[11835914, 11835915, 11835916, 11835917, 11835918, 11835919, 11835920, 11835921, 11835922, 11835923, 11835924, 11835925, 11835926, 11835927, 11835928, 11835929, 11835930, 11835931, 11835932, 11835933, 11835934, 11835935, 11835936, 11835937, 11835938, 11835939, 11835940, 11835941, 11835942, 11835943, 11835944, 11835945, 11835946, 11835947, 11835948, 11835949, 11835950, 11835951, 11835952, 11835953, 11835954, 11835955, 11835956, 11835957, 11835958, 11835959, 11835960, 11835961, 11835962, 11835963, 11835964, 11835965, 11835966, 11835967, 11835968, 11835969, 11835970, 11835971, 11835972, 11835973, 11835974, 11835975, 11835976, 11835977, 11835978, 11835979, 11835980, 11835981, 11835982, 11835983, 11835984, 11835985, 11835986, 11835987, 11835988, 11835989, 11835990, 11835991, 11835992, 11835993, 11835994, 11835995, 11835996, 11835997, 11835998, 11835999, 11836000, 11836001, 11836002, 11836003, 11836004, 11836005, 11836006, 11836007, 11836008, 11836009, 11836010, 11836011, 11836012, 11836013, 11836014, 11836015, 11836016, 11836017, 11836018, 11836019, 11836020, 11836021, 11836022, 11836023, 11836024, 11836025, 11836026, 11836027, 11836028, 11836029, 11836030, 11836031, 11836032, 11836033, 11836034, 11836035, 11836036, 11836037, 11836038, 11836039, 11836040, 11836041, 11836042, 11836043, 11836044, 11836045, 11836046, 11836047, 11836048, 11836049, 11836050, 11836051, 11836052, 11836053, 11836054, 11836055, 11836056, 11836057]\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "expt_name = '2022-10-04_polar_cond'\n",
    "\n",
    "jobs = ps.submit(template, name, list(param_space), work_dir=expt_name, verbose=True)\n",
    "jobs.to_csv(f'{expt_name}.jobs')\n",
    "\n",
    "#import pandas as pd\n",
    "#jobs = pd.read_csv(f'{expt_name}.jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_name</th>\n",
       "      <th>job_state</th>\n",
       "      <th>node_id</th>\n",
       "      <th>runtime</th>\n",
       "      <th>stdout</th>\n",
       "      <th>stderr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11835914</th>\n",
       "      <td>train_50_2D_helmholtz_1_0_0</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>v028</td>\n",
       "      <td>1:07</td>\n",
       "      <td>v028.ib.bridges2.psc.edu\\n/ocean/projects/asc1...</td>\n",
       "      <td>Using backend: pytorch\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11835915</th>\n",
       "      <td>train_50_2D_helmholtz_1_0_1</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>v028</td>\n",
       "      <td>1:07</td>\n",
       "      <td>v028.ib.bridges2.psc.edu\\n/ocean/projects/asc1...</td>\n",
       "      <td>Using backend: pytorch\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11835916</th>\n",
       "      <td>train_50_2D_helmholtz_1_1_0</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>v028</td>\n",
       "      <td>1:07</td>\n",
       "      <td>v028.ib.bridges2.psc.edu\\n/ocean/projects/asc1...</td>\n",
       "      <td>Using backend: pytorch\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11835917</th>\n",
       "      <td>train_50_2D_helmholtz_1_1_1</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>v028</td>\n",
       "      <td>1:07</td>\n",
       "      <td>v028.ib.bridges2.psc.edu\\n/ocean/projects/asc1...</td>\n",
       "      <td>Using backend: pytorch\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11835918</th>\n",
       "      <td>train_50_2D_helmholtz_4_0_0</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>(Priority)</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11836053</th>\n",
       "      <td>train_100_2D_hetero_4_1_1</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>(Priority)</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11836054</th>\n",
       "      <td>train_100_2D_hetero_16_0_0</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>(Priority)</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11836055</th>\n",
       "      <td>train_100_2D_hetero_16_0_1</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>(Priority)</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11836056</th>\n",
       "      <td>train_100_2D_hetero_16_1_0</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>(Priority)</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11836057</th>\n",
       "      <td>train_100_2D_hetero_16_1_1</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>(Priority)</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             job_name job_state     node_id runtime  \\\n",
       "job_id                                                                \n",
       "11835914  train_50_2D_helmholtz_1_0_0   RUNNING        v028    1:07   \n",
       "11835915  train_50_2D_helmholtz_1_0_1   RUNNING        v028    1:07   \n",
       "11835916  train_50_2D_helmholtz_1_1_0   RUNNING        v028    1:07   \n",
       "11835917  train_50_2D_helmholtz_1_1_1   RUNNING        v028    1:07   \n",
       "11835918  train_50_2D_helmholtz_4_0_0   PENDING  (Priority)    0:00   \n",
       "...                               ...       ...         ...     ...   \n",
       "11836053    train_100_2D_hetero_4_1_1   PENDING  (Priority)    0:00   \n",
       "11836054   train_100_2D_hetero_16_0_0   PENDING  (Priority)    0:00   \n",
       "11836055   train_100_2D_hetero_16_0_1   PENDING  (Priority)    0:00   \n",
       "11836056   train_100_2D_hetero_16_1_0   PENDING  (Priority)    0:00   \n",
       "11836057   train_100_2D_hetero_16_1_1   PENDING  (Priority)    0:00   \n",
       "\n",
       "                                                     stdout  \\\n",
       "job_id                                                        \n",
       "11835914  v028.ib.bridges2.psc.edu\\n/ocean/projects/asc1...   \n",
       "11835915  v028.ib.bridges2.psc.edu\\n/ocean/projects/asc1...   \n",
       "11835916  v028.ib.bridges2.psc.edu\\n/ocean/projects/asc1...   \n",
       "11835917  v028.ib.bridges2.psc.edu\\n/ocean/projects/asc1...   \n",
       "11835918                                                NaN   \n",
       "...                                                     ...   \n",
       "11836053                                                NaN   \n",
       "11836054                                                NaN   \n",
       "11836055                                                NaN   \n",
       "11836056                                                NaN   \n",
       "11836057                                                NaN   \n",
       "\n",
       "                              stderr  \n",
       "job_id                                \n",
       "11835914  Using backend: pytorch\\n\\n  \n",
       "11835915  Using backend: pytorch\\n\\n  \n",
       "11835916  Using backend: pytorch\\n\\n  \n",
       "11835917  Using backend: pytorch\\n\\n  \n",
       "11835918                         NaN  \n",
       "...                              ...  \n",
       "11836053                         NaN  \n",
       "11836054                         NaN  \n",
       "11836055                         NaN  \n",
       "11836056                         NaN  \n",
       "11836057                         NaN  \n",
       "\n",
       "[144 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "status_cols = ['job_name', 'job_state', 'node_id', 'runtime', 'stdout', 'stderr']\n",
    "ps.status(jobs)[status_cols] #.iloc[0].stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps.status(jobs)[status_cols].iloc[0].stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ps.metrics(jobs).rename(columns={'mean_abs_value': 'median_abs_value'})\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did all models train to 100k iterations?\n",
    "assert (metrics.groupby('job_name')['iteration'].max() == 250e3).all()\n",
    "\n",
    "param_cols = ['pde_name', 'frequency', 'n_hidden'] # experimental parameters\n",
    "index_cols = ['iteration', 'variable_name', 'spatial_frequency_bin', 'spatial_region'] # metric identifiers\n",
    "metric_cols = ['mean_squared_abs_value', 'power_density', 'median_abs_value'] # metric values\n",
    "\n",
    "group_cols = ['job_name'] + param_cols + index_cols\n",
    "m = metrics.groupby(group_cols, sort=False)[metric_cols].mean() \\\n",
    "    .unstack(level=[group_cols.index('variable_name')])\n",
    "\n",
    "def abbreviate_metrics(t):\n",
    "    metric_name, var_name = t\n",
    "    metric_name = {\n",
    "        'mean_squared_abs_value': 'MSAV',\n",
    "        'median_abs_value': 'MAV',\n",
    "        'power_density': 'PSD'\n",
    "    }[metric_name]\n",
    "    new_col_name = f'{var_name}_{metric_name}'\n",
    "    new_col_name = new_col_name.replace('diff_MSAV', 'pred_MSAE')\n",
    "    new_col_name = new_col_name.replace('f_sum_MSAV', 'PDE_MSAE')\n",
    "    new_col_name = new_col_name.replace('diff_MAV', 'pred_MAD')\n",
    "    return new_col_name\n",
    "\n",
    "m.columns = [abbreviate_metrics(x) for x in m.columns.to_flat_index()]\n",
    "\n",
    "m = m.reset_index()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.spatial_region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the wave field error\n",
    "\n",
    "m['u_pred_MSAE_rel'] = m['u_pred_MSAE'] / m['u_true_MSAV']\n",
    "m['u_pred_MAD_rel'] = m['u_pred_MAD'] / m['u_true_MAV']\n",
    "\n",
    "fig = ps.plot(\n",
    "    m[(m.iteration > 200e3) & ~m.spatial_region.isin({'-1', 'all'})].copy(),\n",
    "    x=param_cols,\n",
    "    y=['u_pred_MAD', 'u_pred_MAD_rel'],\n",
    "    grouped=True,\n",
    "    height=4,\n",
    "    width=3,\n",
    "    legend=True,\n",
    "    tight=True\n",
    ")\n",
    "fig.suptitle('Wave field error', x=0.5, y=0.98)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the elastogram error\n",
    "\n",
    "m['mu_pred_MSAE_rel'] = m['mu_pred_MSAE'] / m['mu_true_MSAV']\n",
    "m['mu_pred_MAD_rel'] = m['mu_pred_MAD'] / m['mu_true_MAV']\n",
    "\n",
    "fig = ps.plot(\n",
    "    m[(m.iteration > 200e3) & ~m.spatial_region.isin({'-1', 'all'})].copy(),\n",
    "    x=param_cols,\n",
    "    y=['mu_pred_MAD', 'mu_pred_MAD_rel'],\n",
    "    grouped=True,\n",
    "    height=4,\n",
    "    width=3,\n",
    "    legend=True,\n",
    "    tight=True\n",
    ")\n",
    "fig.suptitle('Elasticity error', x=0.5, y=0.98)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the Laplacian error (model Laplacian vs finite differences) to assess overfitting\n",
    "\n",
    "m['lu_pred_MSAE_rel'] = m['lu_pred_MSAE'] / m['lu_pred_MSAV']\n",
    "m['lu_pred_MAD_rel'] = m['lu_pred_MAD'] / m['lu_pred_MAV']\n",
    "\n",
    "fig = ps.plot(\n",
    "    m[(m.iteration > 200e3) & ~m.spatial_region.isin({'-1', 'all'})].copy(),\n",
    "    x=param_cols,\n",
    "    y=['lu_pred_MAV', 'lu_pred_MAD_rel'],\n",
    "    grouped=True,\n",
    "    height=4,\n",
    "    width=3,\n",
    "    legend=True,\n",
    "    tight=True\n",
    ")\n",
    "fig.suptitle('Laplacian deviation', x=0.5, y=0.98)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRE-PINN",
   "language": "python",
   "name": "mre-pinn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
